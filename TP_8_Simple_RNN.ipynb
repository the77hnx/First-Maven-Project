{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnxsite/First-Maven-Project/blob/main/TP_8_Simple_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TP 8: Simple **RNN**"
      ],
      "metadata": {
        "id": "xt2F9uajBH73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Convolutional Neural Networks (CNNs) are a class of deep neural networks commonly applied to analyzing visual imagery. They are particularly effective in tasks such as image recognition and classification. CNNs consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers In convolutional layers, filters are applied to input images to extract features such as edges, shapes, and textures. Pooling layers then downsample the features to reduce the computational complexity of the network. The fully connected layers at the end of the network combine the features to make predictions. CNNs use backpropagation to update the weights of the filters during training, optimizing them to better recognize patterns in the data. One of the key advantages of CNNs is their ability to automatically learn features from the data, reducing the need for manual feature engineering. This makes them highly effective in tasks such as image classification, object detection, and facial recognition.\"\n",
        "words = text.split()\n",
        "words = [word.lower() for word in words]\n",
        "word_to_index = {word: i for i, word in enumerate(words)}\n",
        "index_to_word = {i: word for i, word in enumerate(words)}"
      ],
      "metadata": {
        "id": "knQ-6h5EBN_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)"
      ],
      "metadata": {
        "id": "KgqlE9yKie4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 2\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(words) - seq_length):\n",
        "    seq = words[i:i + seq_length]\n",
        "    label = words[i + seq_length]\n",
        "    sequences.append([word_to_index[word] for word in seq])\n",
        "    labels.append(word_to_index[label])\n",
        "\n",
        "print(sequences)\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "B8Mk86HFf14q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "X = np.array(sequences)\n",
        "y = np.array(labels)\n",
        "\n",
        "X_one_hot = tf.one_hot(X, len(words))\n",
        "y_one_hot = tf.one_hot(y, len(words))"
      ],
      "metadata": {
        "id": "XlbJIrmuf7Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(50, input_shape=(seq_length, len(words)), activation='relu'))\n",
        "model.add(Dense(len(words), activation='softmax'))"
      ],
      "metadata": {
        "id": "26b8_zTngj2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LJ-5mWmYg0RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_one_hot, y_one_hot, epochs=100)"
      ],
      "metadata": {
        "id": "EK9SkZ8qg5_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_seq = \"Convolutional Neural\"\n",
        "generated_text = start_seq.lower()\n",
        "\n",
        "for i in range(10):\n",
        "    x = np.array([[word_to_index[word] for word in generated_text.split()[-seq_length:]]])\n",
        "    x_one_hot = tf.one_hot(x, len(words))\n",
        "    prediction = model.predict(x_one_hot)\n",
        "    next_index = np.argmax(prediction)\n",
        "    next_word = index_to_word[next_index]\n",
        "    generated_text += \" \" + next_word\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "iycrunzxhBUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}